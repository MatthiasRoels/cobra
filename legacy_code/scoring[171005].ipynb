{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this script is to output (an)other script(s) with self-contained code to score out a basetable\n",
    "\n",
    "Call this script: the scriptmaker\n",
    "\n",
    "Call the created self-contained script: the scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When code is in script, we define the path of the script's parent folder location as the root directory\n",
    "# From this root we can travel to the relevant folders with minimal adjustment\n",
    "try:\n",
    "    root = os.path.dirname(os.path.realpath(__file__))\n",
    "    root = \"/\".join(root.split('\\\\')[:-1])\n",
    "    log.append('Dynamic paths'+'\\n')\n",
    "except:\n",
    "    root = 'C:/wamp64/www/python_predictions_4/assets/scripts'\n",
    "    log.append('Static paths'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and create variables to be exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1A - Retrieve Modeltab info to find out for which modeltab we want a scoring script for\n",
    "Intermediate step for 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_modeltab = pd.read_csv(root+'/data/univariate/modeltab_info.csv',sep=';', index_col=0, header=None).T\n",
    "modeltabtoscore = df_modeltab.score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1B -  Retrieve number of vars selected to identify which n-th model of the 'modeltab'-models we are interested in\n",
    "Intermediate step for 1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auccurve_path = root+\"/data/modeling/\"+modeltabtoscore+\"_auccurve.csv\"\n",
    "df_auccurve = open(df_auccurve_path).read()\n",
    "selected_nvars = int(re.findall(r\"selected;[0-9]+\",df_auccurve)[0].split(';')[-1])\n",
    "selected_nvars = len(pd.read_csv(df_auccurve_path,skiprows=3, sep=';'))  # USED FOR TESTING ALL VARS, TO BE DELETED !!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1C - Retrieve model coefficients of the specific n-th model of the 'modeltab'-models\n",
    "\n",
    "Result is to be stored in text in the scoring script, to achieve self-containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelcoeff_path = root+\"/data/modeling/\"+modeltabtoscore+\"_modelcoeff.csv\"\n",
    "df_modelcoeff = pd.read_csv(df_modelcoeff_path, sep=';')\n",
    "mask = df_modelcoeff.nstep == int(selected_nvars)\n",
    "df_modrules = df_modelcoeff.loc[mask,:] # TO BE STORED in SCORING SCRIPT -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 - Retrieve Data types of the predictors\n",
    "\n",
    "Result is to be stored in text in the scoring script, to achieve self-containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_path = root+\"/python/data_types.csv\"\n",
    "df_types = pd.read_csv(types_path, header=None)\n",
    "df_types.columns=['var','type'] # TO BE STORED in SCORING SCRIPT ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 - Univariate table output for deriving the translation from original VAR to discretisized D_VAR\n",
    "Result is to be stored in text in the scoring script, to achieve self-containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univariate_path = root+\"/data/univariate/df_univariate.csv\"\n",
    "# we create str converters for all the B_variables coming from the univariate table\n",
    "# we need this because bool & str variables (defined by ...types.csv) from the basetable are converted to objects\n",
    "#  and will have to be compared to the B_variables values, which better have the same type\n",
    "#  e.g. we have a varflag in our basetable which is converted to an object, but assume B_varflag is not converted and will be automatically read as float 1.0/0.0\n",
    "#       in our incidence replacement we will thus be comparing '1'/'0' with 1.0/0.0, which won't work \n",
    "uni_iterable = [(variable,getattr(__builtins__, 'str')) for variable in  'B_'+df_modrules.varname[1:].values]\n",
    "uni_dict = dict(uni_iterable)\n",
    "df_uni = pd.read_csv(df_univariate_path, sep=\";\", converters=uni_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcolumns = ['D_'+name for name in df_modrules.varname[1:]]\n",
    "bcolumns = ['B_'+name for name in df_modrules.varname[1:]]\n",
    "gvar = []\n",
    "gincid = []\n",
    "gbin = []\n",
    "\n",
    "for i in range(len(dcolumns)):\n",
    "    # Select B_varname and D_varname\n",
    "    # Then take unique combinations of B_var and D_var in the univariate dataframe\n",
    "    # These combinations give the incidence value to attribute to the (possibly discretisized/regrouped) variables\n",
    "    columns_set = dcolumns[i:i+1]+bcolumns[i:i+1]\n",
    "    df_dupli = df_uni.loc[:,columns_set].drop_duplicates()\n",
    "    n_occurences = len(df_dupli) \n",
    "    \n",
    "    gvar.extend([df_dupli.columns[0][2:]]*n_occurences)\n",
    "    gincid.extend(df_dupli.iloc[:,0].values)\n",
    "    gbin.extend(df_dupli.iloc[:,1].values)\n",
    "\n",
    "    \n",
    "df_prep = pd.DataFrame({'var':gvar,'bin':gbin,'incid':gincid} \n",
    "                       ,columns=['var','bin','incid']) # TO BE STORED in SCORING SCRIPT --------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing scoring scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_code = open(root+\"/Python/scorecode.R\",'w')\n",
    "\n",
    "score_code.write(\"### Importing libraries & basetable to score\\n\")\n",
    "score_code.write(\"# Importing libraries\\n\")\n",
    "score_code.write(\"#library(dplyr)\\n\")\n",
    "score_code.write(\"# Importing Types\\n\")\n",
    "score_code.write(\"typevariables=c\"+str([var for var in df_types.loc[:,'var']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"typetypes=c\"+str([vartype for vartype in df_types.loc[:,'type']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"df_types=data.frame(var=typevariables,type=typetypes, stringsAsFactors='False')\\n\")\n",
    "score_code.write(\"df_types_copy = df_types\\n\")\n",
    "score_code.write(\"df_types_copy$type[df_types_copy$type=='int'|df_types_copy$type=='float']='numeric'\\n\")\n",
    "score_code.write(\"df_types_copy$type[df_types_copy$type=='str'|df_types_copy$type=='bool']='character'\\n\")\n",
    "score_code.write(\"coltypes = df_types_copy$type\\n\")\n",
    "score_code.write(\"names(coltypes) = df_types_copy$var\\n\")\n",
    "score_code.write(\"# Importing Basetable (with similar typing as in univariate analysis)\\n\")\n",
    "score_code.write(\"df_base = read.csv('df_base.csv', check.names='False', colClasses=coltypes )\\n\")\n",
    "\n",
    "score_code.write(\"### Creating dataframe containing model rules\\n\")\n",
    "score_code.write(\"modvariables=c\"+str([var for var in df_modrules.loc[:,'varname']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"modcoefficients=c\"+str([coeff for coeff in df_modrules.loc[:,'coeff']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"df_modrules=data.frame(varname=modvariables,coeff=modcoefficients, stringsAsFactors='False')\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Creating dataframe containing incidence translation rules\\n\")\n",
    "score_code.write(\"prepvariables=c\"+str([var for var in df_prep.loc[:,'var']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"prepbins=c\"+str([bin for bin in df_prep.loc[:,'bin']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"prepincids=c\"+str([bin for bin in df_prep.loc[:,'incid']]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"df_prep =data.frame(var=prepvariables,bin=prepbins,incid=prepincids, stringsAsFactors='False')\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Grouping basetable predictors along their types and trimming basetable accordingly\\n\")\n",
    "score_code.write(\"predictors = df_modrules$varname[df_modrules$varname!='Intercept']\\n\")\n",
    "score_code.write(\"not_predictors = subset(colnames(df_base),!(colnames(df_base) %in% predictors))\\n\")\n",
    "score_code.write(\"mask_FloatOrInt = df_types$type=='int'|df_types$type=='float'\\n\")\n",
    "score_code.write(\"numeric_headers = subset(df_types$var[mask_FloatOrInt], df_types$var[mask_FloatOrInt] %in% predictors)\\n\")\n",
    "score_code.write(\"object_headers = subset(df_types$var[df_types$type=='str'], df_types$var[df_types$type=='str'] %in% predictors)\\n\")\n",
    "score_code.write(\"bool_headers = subset(df_types$var[df_types$type=='bool'], df_types$var[df_types$type=='bool'] %in% predictors)\\n\")\n",
    "score_code.write(\"df_base = df_base[c(predictors,'ID')]\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Preprocessing the basetable\\n\")\n",
    "score_code.write(\"# Strip quot function\\n\")\n",
    "score_code.write(\"strip_quot<-function(x){\\n\")\n",
    "score_code.write('    x = gsub(\"')\n",
    "score_code.write(\"'\")\n",
    "score_code.write('\",\"\",x)\\n')\n",
    "score_code.write(\"    x = gsub('\")\n",
    "score_code.write('\"')\n",
    "score_code.write(\"','',x)\\n\")               \n",
    "score_code.write(\"    x = trimws(x)\\n\")\n",
    "score_code.write(\"    return(x)\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"# Lower/upper function\\n\")\n",
    "score_code.write(\"lower_upper<-function(x){\\n\")\n",
    "score_code.write(\"    if (tolower(x)=='id'|tolower(x)=='target'){\\n\")\n",
    "score_code.write(\"        x = toupper(x)\\n\")\n",
    "score_code.write(\"    }\\n\")\n",
    "score_code.write(\"    else {\\n\")\n",
    "score_code.write(\"        x = tolower(x)\\n\")\n",
    "score_code.write(\"    }\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"# maskmissing function in str/bool columns\\n\")\n",
    "score_code.write(\"maskmissing<-function(var){\\n\")\n",
    "score_code.write(\"    crit1 = is.na(var)\\n\")\n",
    "score_code.write(\"    crit2 = var==''\\n\")\n",
    "score_code.write(\"    return(crit1|crit2)\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"# Apply preprocessing functions\\n\")\n",
    "score_code.write(\"colnames(df_base) = sapply(colnames(df_base), lower_upper)\\n\")\n",
    "score_code.write(\"colnames(df_base) = sapply(colnames(df_base), strip_quot)\\n\")\n",
    "score_code.write(\"df_base[] = lapply(df_base, strip_quot)\\n\")\n",
    "score_code.write(\"for (predictor in c(object_headers,bool_headers)){\\n\")\n",
    "score_code.write(\"    df_base[maskmissing(df_base[predictor]),predictor]='Missing'\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Incidence replacement\\n\")\n",
    "score_code.write(\"# Recipient dataframe\\n\")\n",
    "score_code.write(\"df_out = data.frame(ID=df_base$ID)\\n\")\n",
    "score_code.write(\"# Incidence replacement for string columns\\n\")\n",
    "score_code.write(\"for (header in c(object_headers,bool_headers)){\\n\")\n",
    "score_code.write(\"    mask = df_prep$var==header\\n\")\n",
    "score_code.write(\"    bins = df_prep[mask,'bin']\\n\")\n",
    "score_code.write(\"    incidences = df_prep[mask,'incid']\\n\")\n",
    "score_code.write(\"    nonsig_bins = c()\\n\")\n",
    "score_code.write(\"    nonsig_incidences = c()\\n\")\n",
    "score_code.write(\"    if (sum(bins == 'Non-significants')>0) {\\n\")\n",
    "score_code.write(\"        nonsig_bins = subset(unique(df_base[,header]), !(unique(df_base[,header]) %in% bins))\\n\")\n",
    "score_code.write(\"        nonsig_incidences = rep(incidences[bins=='Non-significants'],length(nonsig_bins))\\n\")\n",
    "score_code.write(\"    }\\n\")\n",
    "score_code.write(\"    keys = c(bins,nonsig_bins)\\n\")\n",
    "score_code.write(\"    values = c(incidences,nonsig_incidences)\\n\")\n",
    "score_code.write(\"    df_out[paste('D_',header, sep='')] = values[match(df_base[,header], keys)]\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"# Incidence replacement for numeric columns\\n\")\n",
    "score_code.write(\"for (header in numeric_headers){\\n\")\n",
    "score_code.write(\"    mask = df_prep$var==header\\n\")\n",
    "score_code.write(\"    bins = df_prep[mask,'bin']\\n\")\n",
    "score_code.write(\"    incidences = df_prep[mask,'incid']\\n\")\n",
    "score_code.write(\"    index_missing = which(bins=='Missing')\\n\")\n",
    "score_code.write(\"    incidence_missing = incidences[index_missing]\\n\")\n",
    "score_code.write(\"    upper_values = c()\\n\")\n",
    "score_code.write(\"    last <- function(x) { return( x[length(x)] ) }\\n\")\n",
    "score_code.write(\"    for (binn in bins){\\n\")\n",
    "score_code.write(\"        upper_value = last(unlist(strsplit(binn,',')))\\n\")\n",
    "score_code.write(\"        upper_value = tryCatch(as.numeric(gsub('([0-9]+).*$', '\\\\\")\n",
    "score_code.write(\"\\\\\")\n",
    "score_code.write(\"1',upper_value)), warning=function(e) Inf)\\n\")\n",
    "score_code.write(\"        upper_values = c(upper_values,upper_value)\\n\")\n",
    "score_code.write(\"    }\\n\")\n",
    "score_code.write(\"    if(!identical(index_missing,integer(0))) upper_values = upper_values[-index_missing]\\n\")\n",
    "score_code.write(\"    if(!identical(index_missing,integer(0))) incidences = incidences[-index_missing]\\n\")\n",
    "score_code.write(\"    upper_values_incidences = incidences[order(upper_values)]\\n\")\n",
    "score_code.write(\"    upper_values = upper_values[order(upper_values)]\\n\")\n",
    "#score_code.write(\"    incidence_replaced_values = c()\\n\")\n",
    "#score_code.write(\"    for (original_value in as.numeric(df_base[,header])){\\n\")\n",
    "#score_code.write(\"        if (is.na(original_value)){\\n\")\n",
    "#score_code.write(\"            incidence_to_attribute = incidence_missing\\n\")\n",
    "#score_code.write(\"        }\\n\")\n",
    "#score_code.write(\"        else {\\n\")\n",
    "#score_code.write(\"            lowest_membership = min(which(original_value<=upper_values))\\n\")\n",
    "#score_code.write(\"            incidence_to_attribute = upper_values_incidences[lowest_membership]\\n\")\n",
    "#score_code.write(\"        }\\n\")\n",
    "#score_code.write(\"        incidence_replaced_values = c(incidence_replaced_values,incidence_to_attribute)\\n\")\n",
    "#score_code.write(\"    }\\n\")\n",
    "#score_code.write(\"    df_out[paste('D_',header, sep='')] = incidence_replaced_values\\n\")\n",
    "score_code.write(\"    mask_nan = is.na(df_base[,header])\\n\")\n",
    "score_code.write(\"    lowest_memberships = findInterval(as.numeric(df_base[,header]), upper_values * (1 + .Machine$double.eps)) + 1\\n\")\n",
    "score_code.write(\"    incidences_to_attribute = upper_values_incidences[lowest_memberships]\\n\")\n",
    "score_code.write(\"    incidences_to_attribute[mask_nan] = incidence_missing\\n\")\n",
    "score_code.write(\"    df_out[paste('D_',header, sep='')] = incidences_to_attribute\\n\")\n",
    "score_code.write(\"}\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Scoring\\n\")\n",
    "score_code.write(\"df_scores = data.frame(ID=as.numeric(as.character(df_out$ID)))\\n\")\n",
    "score_code.write(\"scores = c()\\n\")\n",
    "score_code.write(\"intercept=\"+str(df_modrules.coeff.values[0])+\"\\n\")\n",
    "score_code.write(\"coefficients=c\"+str([coeff for coeff in df_modrules.coeff][1:]).replace(\"[\",\"(\").replace(\"]\",\")\")+\"\\n\")\n",
    "score_code.write(\"productsums = rowSums(t(t(df_out[,paste('D_',predictors,sep='')])*coefficients))\\n\")\n",
    "score_code.write(\"exponents = intercept + productsums\\n\")\n",
    "score_code.write(\"scores = sapply(exponents, FUN = function(x) (exp(x)) / (1+exp(x)))\\n\")\n",
    "score_code.write(\"df_scores['score']=scores\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_code = open(root+\"/Python/scorecode.py\",'w')\n",
    "\n",
    "score_code.write(\"### Importing libraries & basetable to score\\n\")\n",
    "score_code.write(\"# Importing Libraries\\n\")\n",
    "score_code.write(\"import time\\nimport math\\nimport csv\\nimport re\\nimport pandas as pd\\nimport numpy as np\\n\")\n",
    "score_code.write(\"# Importing Types\\n\")\n",
    "score_code.write(\"typevariables=\"+str([var for var in df_types.loc[:,'var']])+\"\\n\")\n",
    "score_code.write(\"typetypes=\"+str([vartype for vartype in df_types.loc[:,'type']])+\"\\n\")\n",
    "score_code.write(\"df_types=pd.DataFrame({'var':typevariables,'type':typetypes},columns=['var','type'])\\n\")\n",
    "score_code.write(\"df_types_copy = df_types.copy()\\n\")\n",
    "score_code.write(\"bool_mask = df_types_copy.loc[:,'type']!='bool'\\n\")\n",
    "score_code.write(\"df_types_copy.loc[bool_mask,'type'] = [getattr(__builtins__, type_str) for type_str in df_types_copy.loc[bool_mask,'type']]\\n\")\n",
    "score_code.write(\"df_types_copy.loc[bool_mask==False,'type'] = getattr(__builtins__, 'str')\\n\")\n",
    "score_code.write(\"types = df_types_copy.set_index('var').T.to_dict('records')\\n\")                 \n",
    "score_code.write(\"# Importing Basetable with similar typing as in univariate analysis\\n\")\n",
    "score_code.write(\"df_base = pd.read_csv('df_base.csv',header=0,sep=None,engine='python',converters=types[0])\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Creating dataframe containing model rules\\n\")\n",
    "score_code.write(\"modvariables=\"+str([var for var in df_modrules.loc[:,'varname']])+\"\\n\")\n",
    "score_code.write(\"modcoefficients=\"+str([coeff for coeff in df_modrules.loc[:,'coeff']])+\"\\n\")\n",
    "score_code.write(\"df_modrules=pd.DataFrame({'varname':modvariables,'coeff':modcoefficients})\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Creating dataframe containing incidence translation rules\\n\")\n",
    "score_code.write(\"prepvariables=\"+str([var for var in df_prep.loc[:,'var']])+\"\\n\")\n",
    "score_code.write(\"prepbins=\"+str([bin for bin in df_prep.loc[:,'bin']])+\"\\n\")\n",
    "score_code.write(\"prepincids=\"+str([bin for bin in df_prep.loc[:,'incid']])+\"\\n\")\n",
    "score_code.write(\"df_prep = pd.DataFrame({'var':prepvariables,'bin':prepbins,'incid':prepincids}, dtype=object)\\n\")\n",
    "score_code.write(\"df_prep.loc[:,'incid']=df_prep.loc[:,'incid'].astype('float64')\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Grouping basetable predictors along their types and trimming basetable accordingly\\n\")\n",
    "score_code.write(\"predictors = list(df_modrules.loc[df_modrules.varname!='Intercept','varname'].values)\\n\")\n",
    "score_code.write(\"not_predictors = [column for column in df_base.columns if column not in predictors]\\n\")\n",
    "score_code.write(\"mask_FloatOrInt = (df_types.type=='int')|(df_types.type=='float')\\n\")\n",
    "score_code.write(\"numeric_headers=[var for var in df_types.loc[mask_FloatOrInt,'var'].values if var in predictors]\\n\")\n",
    "score_code.write(\"object_headers=[var for var in df_types.loc[df_types.type=='str','var'].values if var in predictors]\\n\")\n",
    "score_code.write(\"bool_headers=[var for var in df_types.loc[df_types.type=='bool','var'].values if var in predictors]\\n\")\n",
    "score_code.write(\"df_base = df_base[predictors+['ID']]\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.write(\"### Preprocessing the basetable\\n\")\n",
    "score_code.write(\"# Strip quot function\\n\")\n",
    "score_code.write(\"def strip_quot(x_in):\\n\")\n",
    "score_code.write(\"    try:\\n\")\n",
    "score_code.write(\"        x_out = x_in.strip().strip('\")\n",
    "score_code.write('\"')\n",
    "score_code.write(\"').strip(\")\n",
    "score_code.write('\"')\n",
    "score_code.write(\"'\")\n",
    "score_code.write('\")\\n')\n",
    "score_code.write(\"    except:\\n\")\n",
    "score_code.write(\"        x_out=x_in\\n\")\n",
    "score_code.write(\"    return x_out\\n\")\n",
    "score_code.write(\"# Lower/upper function\\n\")\n",
    "score_code.write(\"def lower_upper(x_in):\\n\")\n",
    "score_code.write(\"    if ((x_in.lower() == 'id')|(x_in.lower() == 'target')):\\n\")\n",
    "score_code.write(\"        x_out = x_in.upper()\\n\")\n",
    "score_code.write(\"    else:\\n\")\n",
    "score_code.write(\"        x_out = x_in.lower()\\n\")\n",
    "score_code.write(\"    return x_out\\n\")\n",
    "score_code.write(\"# maskmissing function in str/bool columns\\n\")\n",
    "score_code.write(\"def maskmissing(var):\\n\")\n",
    "score_code.write(\"    crit1 = var.isnull()\\n\")\n",
    "score_code.write(\"    modvar = pd.Series([str(value).strip() for value in var])\\n\")\n",
    "score_code.write(\"    crit2 = modvar==pd.Series(['']*len(var))\\n\")\n",
    "score_code.write(\"    return crit1 | crit2\\n\")\n",
    "score_code.write(\"# Apply preprocessing functions\\n\")\n",
    "score_code.write(\"df_base = df_base.rename(columns=strip_quot)\\n\")\n",
    "score_code.write(\"df_base = df_base.rename(columns=lower_upper)\\n\")\n",
    "score_code.write(\"df_base = df_base.applymap(strip_quot)\\n\")\n",
    "score_code.write(\"for header in object_headers+bool_headers:\\n\")\n",
    "score_code.write(\"    mask = maskmissing(df_base[header])\\n\")\n",
    "score_code.write(\"    df_base.loc[mask,header]='Missing'\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "                 \n",
    "score_code.write(\"### Incidence replacement\\n\")\n",
    "score_code.write(\"# Recipient dataframe\\n\")\n",
    "score_code.write(\"df_out = pd.DataFrame()\\n\")\n",
    "score_code.write(\"df_out['ID']=df_base['ID']\\n\")\n",
    "score_code.write(\"# Incidence replacement for string columns\\n\")\n",
    "score_code.write(\"for header in object_headers+bool_headers:\\n\")\n",
    "score_code.write(\"    mask = df_prep.loc[:,'var']==header\\n\")\n",
    "score_code.write(\"    bins = df_prep.loc[mask,'bin']\\n\")\n",
    "score_code.write(\"    incidences = df_prep.loc[mask,'incid']\\n\")\n",
    "score_code.write(\"    nonsig_bins = []\\n\")\n",
    "score_code.write(\"    nonsig_incidences = []\\n\")\n",
    "score_code.write(\"    if (bins == 'Non-significants').any():\\n\")\n",
    "score_code.write(\"        nonsig_bins = [binn for binn in df_base[header].unique() if binn not in list(bins)]\\n\")\n",
    "score_code.write(\"        nonsig_incidences = list(incidences[bins=='Non-significants'])*len(nonsig_bins)\\n\")\n",
    "score_code.write(\"    keys = list(bins)\\n\")\n",
    "score_code.write(\"    keys.extend(nonsig_bins)\\n\")\n",
    "score_code.write(\"    values = list(incidences)\\n\")\n",
    "score_code.write(\"    values.extend(nonsig_incidences)\\n\")\n",
    "score_code.write(\"    keys_and_values = zip(keys,values)\\n\")\n",
    "score_code.write(\"    transdic = dict(keys_and_values)\\n\")\n",
    "score_code.write(\"    items_to_translate = df_base[header] \\n\")\n",
    "score_code.write(\"    df_out.loc[:,'D_'+header]= pd.Series([transdic[item] for item in items_to_translate])\\n\")\n",
    "score_code.write(\"# Incidence replacement for numeric columns\\n\")\n",
    "score_code.write(\"for header in numeric_headers:\\n\")\n",
    "score_code.write(\"    mask = df_prep.loc[:,'var']==header\\n\")\n",
    "score_code.write(\"    bins = df_prep.loc[mask,'bin']\\n\")\n",
    "score_code.write(\"    incidences = df_prep.loc[mask,'incid']\\n\")\n",
    "score_code.write(\"    index_missing = bins.index[bins=='Missing']\\n\")\n",
    "score_code.write(\"    incidence_missing = incidences[index_missing]\\n\")\n",
    "score_code.write(\"    upper_values = pd.Series([])\\n\")\n",
    "score_code.write(\"    for i,binn in enumerate(bins.values):\\n\")\n",
    "score_code.write(\"        upper_value = binn.split(',')[-1]\\n\")\n",
    "score_code.write(\"        try:\\n\")\n",
    "score_code.write(\"            upper_value = re.findall('[0-9]+',upper_value)[0]\\n\")\n",
    "score_code.write(\"        except:\\n\")\n",
    "score_code.write(\"            upper_value = math.inf\\n\")\n",
    "score_code.write(\"        upper_values[i] = upper_value\\n\")\n",
    "score_code.write(\"    upper_values.index = bins.index\\n\")\n",
    "score_code.write(\"    upper_values.drop(index_missing, inplace=True)\\n\")\n",
    "score_code.write(\"    upper_values = upper_values.astype(float)\\n\")\n",
    "score_code.write(\"    upper_values.sort_values(inplace=True)\\n\")\n",
    "score_code.write(\"    upper_values_incidences = incidences[upper_values.index]\\n\")\n",
    "score_code.write(\"    upper_values.reset_index(drop=True, inplace=True)\\n\")\n",
    "score_code.write(\"    upper_values_incidences.reset_index(drop=True, inplace=True)\\n\")\n",
    "#score_code.write(\"    incidence_replaced_values = np.array([])\\n\")\n",
    "#score_code.write(\"    for original_value in df_base[header]:\\n\")\n",
    "#score_code.write(\"        lowest_membership = upper_values.index[original_value<=upper_values].min()\\n\")\n",
    "#score_code.write(\"        try:\\n\")\n",
    "#score_code.write(\"            incidence_to_attribute = upper_values_incidences[lowest_membership]\\n\")\n",
    "#score_code.write(\"        except:\\n\")\n",
    "#score_code.write(\"            if np.isnan(original_value):\\n\")\n",
    "#score_code.write(\"                incidence_to_attribute = incidence_missing\\n\")\n",
    "#score_code.write(\"            else:\\n\")\n",
    "#score_code.write(\"                incidence_to_attribute = np.nan\\n\")\n",
    "#score_code.write(\"        incidence_replaced_values = np.append(incidence_replaced_values,incidence_to_attribute)\\n\")\n",
    "#score_code.write(\"    df_out['D_'+header] = pd.Series(incidence_replaced_values)\\n\")\n",
    "score_code.write(\"    mask_npnan = df_base.loc[:,header].isnull()\\n\")\n",
    "score_code.write(\"    lowest_memberships = upper_values.searchsorted(df_base.loc[:,header],side='left')\\n\")\n",
    "score_code.write(\"    incidences_to_attribute = upper_values_incidences[lowest_memberships].reset_index(drop=True)\\n\")\n",
    "score_code.write(\"    incidences_to_attribute[mask_npnan] = incidence_missing\\n\")\n",
    "score_code.write(\"    df_out['D_'+header] = incidences_to_attribute\\n\")\n",
    "score_code.write(\"\\n\")    \n",
    "\n",
    "                 \n",
    "score_code.write(\"### Scoring\\n\")\n",
    "score_code.write(\"df_scores = pd.DataFrame([])\\n\")\n",
    "score_code.write(\"df_scores['ID'] = df_out['ID']\\n\")\n",
    "score_code.write(\"scores = []\\n\")\n",
    "score_code.write(\"intercept=\"+str(df_modrules.coeff.values[0])+\"\\n\")\n",
    "score_code.write(\"coefficients=np.array(\"+str([coeff for coeff in df_modrules.coeff][1:])+\")\\n\")\n",
    "score_code.write(\"productsums = (df_out['D_'+pd.Series(predictors)]*coefficients).sum(axis=1)\\n\")\n",
    "score_code.write(\"exponents = intercept + productsums\\n\")\n",
    "score_code.write(\"scores = exponents.apply(func=lambda x:(math.exp(x)) / (1+math.exp(x)))\\n\")\n",
    "score_code.write(\"df_scores['score']=scores\\n\")\n",
    "score_code.write(\"\\n\")\n",
    "\n",
    "score_code.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for Sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
